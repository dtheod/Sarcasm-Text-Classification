{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import transformers\n",
    "from transformers import DistilBertTokenizerFast\n",
    "import matplotlib.pyplot as plt\n",
    "from statistics import mean\n",
    "import os\n",
    "import csv\n",
    "import random\n",
    "import operator\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import warnings\n",
    "import numpy as np\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Sarcasm Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "comments = []\n",
    "labels = []\n",
    "\n",
    "with open(os.path.join(os.getcwd(),'data/sarcasm.json')) as file:\n",
    "    data = json.load(file)\n",
    "    comments_labels = [(row['is_sarcastic'], row['headline']) for row in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_labels[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Term Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def term_frequency(comments_labels):\n",
    "    nltk.download(\"stopwords\", quiet=True)\n",
    "    stop_words = stopwords.words(\"english\")\n",
    "    just_sentences = [sentence for label, sentence in comments_labels]    \n",
    "    tf_dict = {}\n",
    "    for sentence in just_sentences:\n",
    "        sentence = re.sub(r\"[^a-zA-Z]\", \" \", sentence.lower())\n",
    "        split_words = sentence.split(\" \")\n",
    "        for word in split_words:\n",
    "            if word not in stop_words and str(word) not in ['nan', '']:\n",
    "                tf_dict[word] = tf_dict.setdefault(word, 0) + 1\n",
    "    return sorted(tf_dict.items(), key=operator.itemgetter(1),reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_frequency = term_frequency(comments_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar([x for x,y in term_frequency[:10]], [y for x,y in term_frequency[:10]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Text Cleaning-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = comments_labels[:int((len(comments_labels)+1)*.80)]\n",
    "validation_data = comments_labels[int(len(comments_labels)*.80+1):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(comments_labels):\n",
    "    import re\n",
    "    sentences = [(te, te1) for te, te1 in comments_labels if str(te) not in ['nan', '']]\n",
    "    reduced_sentences = [(te, te1) for te, te1 in sentences if len(te1.split(\" \")) >= 5]\n",
    "    new_sentences = [(te,re.sub(r\"[^a-zA-Z0-9]\", \" \", te1.lower())) for te, te1 in reduced_sentences]\n",
    "    return [te1 for te, te1 in new_sentences], [int(te) for te, te1 in new_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text, train_labels = preprocessing(train_data)\n",
    "validation_text, validation_labels = preprocessing(validation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import BERT models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizerFast\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "train_encodings = tokenizer(train_text, truncation = True, padding = True, max_length = 50)\n",
    "validation_encodings = tokenizer(validation_text, truncation = True, padding = True, max_length = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_encodings),\n",
    "    train_labels\n",
    "))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(validation_encodings),\n",
    "    validation_labels\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFDistilBertForSequenceClassification\n",
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=5e-5)\n",
    "model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)\n",
    "model.compile(optimizer=optimizer, loss=model.compute_loss, metrics=['accuracy'])\n",
    "model.fit(train_dataset.shuffle(1000).batch(16),\n",
    "          epochs=3,\n",
    "          batch_size=16,\n",
    "          validation_data=val_dataset.shuffle(1000).batch(16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(os.path.join(os.getcwd(),\"model/sarcasm_bert_model.h5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Model with Convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 1000\n",
    "embedding_dim = 16\n",
    "max_length = 120\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<OOV>\"\n",
    "training_size = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(train_text)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "training_sequences = tokenizer.texts_to_sequences(train_text)\n",
    "training_padded = pad_sequences(training_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "testing_sequences = tokenizer.texts_to_sequences(validation_text)\n",
    "testing_padded = pad_sequences(testing_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_custom = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.Conv1D(128, 5, activation='relu'),\n",
    "    tf.keras.layers.GlobalMaxPooling1D(),\n",
    "    tf.keras.layers.Dense(24, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_custom.compile(loss='binary_crossentropy',optimizer='rmsprop',metrics=['accuracy'])\n",
    "model_custom.summary()\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "training_padded = np.array(training_padded)\n",
    "training_labels = np.array(train_labels)\n",
    "testing_padded = np.array(testing_padded)\n",
    "testing_labels = np.array(validation_labels)\n",
    "\n",
    "model_custom.fit(training_padded, training_labels, epochs=num_epochs,\n",
    "          validation_data=(testing_padded, testing_labels), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence = \"With their homes in ashes, residents share harrowing tales of survival after massive wildfires kill 15\"\n",
    "test_sentence_sarcasm = \"So Im guessing you didn't get the part or Italy called and said it was hungry?\"\n",
    "# replace to test_sentence_sarcasm variable, if you want to test \n",
    "# sarcasm\n",
    "predict_input = tokenizer.encode(test_sentence_sarcasm,\n",
    "                                 truncation=True,\n",
    "                                 padding=True,\n",
    "                                 return_tensors=\"tf\")\n",
    "tf_output = model.predict(predict_input)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_prediction = tf.nn.softmax(tf_output, axis=1).numpy()[0]\n",
    "if tf_prediction[1] > tf_prediction[0]:\n",
    "    print(\"Sentence is Sarcasm\")\n",
    "else:\n",
    "    print(\"Sentence is not Sarcasm\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "miniforge3",
   "language": "python",
   "name": "miniforge3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
